{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python3.5/site-packages/theano/tensor/signal/downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.\n",
      "  \"downsample module has been moved to the theano.tensor.signal.pool module.\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import scipy.sparse as sp\n",
    "from theano import sparse\n",
    "import lasagne\n",
    "import time\n",
    "import scipy.stats as stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate a matrix from a multivariate normal distribution with low-rank covariance matrix\n",
    "KTRUE = 10\n",
    "K = 20\n",
    "N = 100\n",
    "D = 50\n",
    "maxit = 3*KTRUE*(N+D-KTRUE)\n",
    "\n",
    "np.random.seed(seed=10)\n",
    "\n",
    "w   = np.random.uniform(low=0.0, high=1.0, size=(D,KTRUE))\n",
    "var = 0.1\n",
    "covnp = w.dot(w.T)+var*np.eye(D)\n",
    "\n",
    "Mnp = np.random.multivariate_normal(np.zeros(D), covnp, N).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We use Theano for our model\n",
    "srng = T.shared_randomstreams.RandomStreams(seed=120)\n",
    "\n",
    "#Define Theano Variables\n",
    "Shared = lambda shape,name: theano.shared(value = np.ones(shape,dtype=theano.config.floatX),\n",
    "                                          name=name,borrow=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let Ynp represent our matrix of partial, noisy observations\n",
    "p      = (maxit/20)/(N*D)\n",
    "#Masknp = np.random.binomial(N, p, size=(N,D)).T\n",
    "Masknp = stats.bernoulli.rvs(p, size=(D,N))\n",
    "Mask   = T.as_tensor_variable(Masknp)\n",
    "M      = T.as_tensor_variable(Mnp)\n",
    "Y      = Mask*M\n",
    "zeroY  = T.as_tensor_variable(np.zeros((D,N)))\n",
    "zero2  = T.as_tensor_variable(np.zeros((D,D)))\n",
    "zero   = T.as_tensor_variable(np.zeros(D))\n",
    "st     = T.sum(T.neq(Y, zeroY), axis = 0)\n",
    "s      = st.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.042"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N*D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Define variational parameters\n",
    "mW=Shared((D,K), \"mW\")\n",
    "sW=Shared((D,K), \"sW\")\n",
    "mr=Shared((K), \"mr\")\n",
    "sr=Shared((K), \"sr\")\n",
    "mGamma=Shared((1), \"mGamma\")\n",
    "sGamma=Shared((1), \"sGamma\")\n",
    "mGamma0=Shared((1), \"mGamma0\")\n",
    "sGamma0=Shared((1), \"sGamma0\")\n",
    "mc0=Shared((1), \"mc0\")\n",
    "sc0=Shared((1), \"sc0\")\n",
    "msigma=Shared((1), \"msigma\")\n",
    "ssigma=Shared((1), \"ssigma\")\n",
    "\n",
    "#Define model parameters and other random variables (zY, zK, error, KmatrixRandom)\n",
    "zW= srng.normal((D,K))\n",
    "zr= srng.normal([K])\n",
    "zGamma= srng.normal([1])\n",
    "zGamma0= srng.normal([1])\n",
    "zc0= srng.normal([1])\n",
    "zsigma=srng.normal([1])\n",
    "zY=srng.normal([D])\n",
    "zK=srng.normal([K])\n",
    "KmatrixRandom=srng.uniform(size=(D,D), low=0, high=1000)\n",
    "\n",
    "#All variables have a log-normal variational posterior\n",
    "W=T.exp(mW+0.1*sW)\n",
    "r=T.exp(mr + zr*sr)\n",
    "Gamma=T.exp(mGamma + zGamma*sGamma)\n",
    "Gamma0=T.exp(mGamma0 + zGamma0*sGamma0)\n",
    "c0=T.exp(mc0 + zc0*sc0)\n",
    "sigma=T.exp(msigma +zsigma*ssigma)\n",
    "\n",
    "\n",
    "#For data given seqentially we need a different covariance matrix for each yn\n",
    "WWT=T.dot(W, W.T)\n",
    "Cov=Shared((D,D), 'Cov')\n",
    "Cov=WWT+sigma[0]*T.identity_like(WWT)\n",
    "\n",
    "\n",
    "#Define lists\n",
    "vParams= [mW, sW, mr, sr, mGamma, sGamma, mGamma0, sGamma0, mc0, sc0, msigma, ssigma]\n",
    "mParams = [W, r, Gamma, Gamma0, c0, sigma]\n",
    "\n",
    "#indexlist = Shared([maxit], 'indexlist')\n",
    "indexlist = theano.shared(value = np.zeros([maxit],dtype=np.int64),\n",
    "                                          name='indexlist',borrow=True)\n",
    "\n",
    "Estimates = Shared((maxit, N, D), 'Estimates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define Functions for Variational Inference\n",
    "\n",
    "def Entropy(vParams):\n",
    "    \n",
    "    mW, sW, mr, sr, mGamma, sGamma, mGamma0, sGamma0, mc0, sc0, msigma, ssigma= vParams\n",
    "    entW      = T.log(T.abs_(sW))+mW\n",
    "    entr      = T.log(T.abs_(sr))+mr\n",
    "    entGamma  = T.log(T.abs_(sGamma))+mGamma\n",
    "    entGamma0 = T.log(T.abs_(sGamma0))+mGamma0\n",
    "    entc0     = T.log(T.abs_(sc0))+mc0\n",
    "    entsigma  = T.log(T.abs_(ssigma))+msigma\n",
    "    entropy   = entW.sum()+entr.sum()+entGamma+entGamma0+entc0+entsigma\n",
    "    \n",
    "    return(entropy)\n",
    "\n",
    "\n",
    "\n",
    "def logJointScanFn2(n, logLikelihood, Y, Cov, s):\n",
    "    \n",
    "    idxs          = T.neq(Y[:,n], zero).nonzero()\n",
    "    y             = Y[:,n][idxs]\n",
    "    idxs2         = T.neq(T.outer(Y[:,n], Y[:,n]), zero2).nonzero()\n",
    "    littlecov     = Cov[idxs2].reshape((s[n], s[n]))\n",
    "    logLikelihood +=(-1/2.0)*T.log(T.nlinalg.Det()(littlecov))-(1/2.0)*T.dot(y.T, T.dot(T.nlinalg.MatrixInverse()(littlecov), y))\n",
    "    \n",
    "    return logLikelihood\n",
    "\n",
    "\n",
    "\n",
    "def LogJ2(mParams,vParams,Y, Cov, s):\n",
    "    \n",
    "    mW, sW, mr, sr, mGamma, sGamma, mGamma0, sGamma0, mc0, sc0, msigma, ssigma = vParams\n",
    "    W, r, Gamma, Gamma0, c0, sigma = mParams\n",
    "    #LogJt0=time.clock()\n",
    "    results, updates = theano.scan(fn=logJointScanFn2,\n",
    "                                   sequences = np.arange(N),\n",
    "                                   outputs_info=[dict(initial= np.float64(0) ,taps=[-1])],\n",
    "                                   non_sequences=[Y, Cov, s])\n",
    "    logJoint  = results[-1]\n",
    "    logJoint2 = ((D*Gamma*T.log(Gamma))[0]*r).sum()-(D*T.gammaln(Gamma[0]*r)).sum()+((Gamma[0]*r-1)*T.log(W)).sum()-(Gamma[0]*W).sum() + (Gamma0*T.log(c0)-K*T.gammaln(Gamma0/K)+(Gamma0/K-1)[0]*(T.log(r)).sum()-(c0[0]*r).sum()-Gamma-Gamma0-c0)[0]\n",
    "    logJoint  += logJoint2\n",
    "\n",
    "    return(logJoint)\n",
    "\n",
    "\n",
    "    \n",
    "def ELBO(mParams,vParams, Y, Cov, s):\n",
    "    \n",
    "    return(LogJ2(mParams,vParams, Y, Cov, s)+Entropy(vParams)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "elbo    = ELBO(mParams,vParams,Y,Cov, s)\n",
    "entropy = Entropy(vParams)\n",
    "logJ    = LogJ2(mParams,vParams,Y,Cov, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Ytrue = Y.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Stochastic Gradient Descent\n",
    "\n",
    "elbo=ELBO(mParams,vParams, Y, Cov, s)\n",
    "entropy=Entropy(vParams)\n",
    "logJ=LogJ2(mParams,vParams, Y, Cov, s)\n",
    "#paramt0=time.clock()\n",
    "vParamUpdates=lasagne.updates.adadelta(-elbo,vParams)\n",
    "#paramt1=time.clock()\n",
    "AdaDeltaStep=theano.function(inputs=[], updates=vParamUpdates)\n",
    "\n",
    "\n",
    "def SGD(Y, limit,construct_elbo_list, construct_error_list):\n",
    "    \n",
    "    #Repeat Code as above to construct the partial covariance matrices, also construct binaryY\n",
    "    #which is a matrix with a 1 in the (i,j) entry if we have observed that entry\n",
    "    elbo=ELBO(mParams,vParams, Y, Cov, s)\n",
    "    entropy=Entropy(vParams)\n",
    "    logJ=LogJ2(mParams,vParams, Y, Cov, s)\n",
    "    #paramt0=time.clock()\n",
    "    vParamUpdates=lasagne.updates.adadelta(-elbo,vParams)\n",
    "    #paramt1=time.clock()\n",
    "\n",
    "    \n",
    "    #%%time\n",
    "    counter = 0\n",
    "    ELBOlist = []\n",
    "    errorlist = []\n",
    "    keepUpdating = True\n",
    "    if construct_elbo_list==1:\n",
    "        while keepUpdating:\n",
    "            AdaDeltaStep()\n",
    "            keepUpdating = False if counter>limit else True \n",
    "            # if construct_elbo_list==1, estimate ELBO by Monte Carlo every 20 steps\n",
    "            if counter%20==0:\n",
    "                ELBOlist.append(np.mean([elbo.eval() for i in range(40)]))\n",
    "                R = 10\n",
    "                [y_estimate, sigma_u_o_scan, sigma_ob_inv_scan], updates=theano.scan(fn=MVNormalScan_beta02,\n",
    "                                              sequences=T.arange(N),\n",
    "                                              outputs_info=None,\n",
    "                                              non_sequences=[Y, Mask, Cov, W, zY, zK, s])\n",
    "                Yest = y_estimate.eval().T\n",
    "                errorlist.append(np.linalg.norm(Yest- Ytrue))                \n",
    "            counter +=1\n",
    "    else:\n",
    "        while keepUpdating:\n",
    "            AdaDeltaStep()\n",
    "            keepUpdating = False if counter>limit else True \n",
    "            counter += 1\n",
    "    print(counter)\n",
    "    \n",
    "    return ELBOlist, errorlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#MVNormalScan constructs our estimate of the entire matrix using conditional multivariate normal\n",
    "\n",
    "def MVNormalScan_beta02(n, Y, Mask, Cov, W, zY, zK, s):\n",
    "    \n",
    "    #construct binaryY_unobs a vector of 1s and 0s where the ith coord is a 1 if we haven't seen the ith coord of y_n    \n",
    "    binaryY_unobs = T.eq(Y[:,n], zero)\n",
    "    #construct covariance of the observed entries where the rows/columns with nothing have a 1 on diag (so invertible)\n",
    "    idxs          = T.neq(Y[:,n], zero).nonzero()\n",
    "    y             = Y[:,n][idxs]\n",
    "    idxs2         = T.neq(T.outer(Y[:,n], Y[:,n]), zero2).nonzero()\n",
    "    littlecov     = Cov[idxs2].reshape((s[n], s[n]))\n",
    "    littlecov_inv = T.nlinalg.MatrixInverse()(littlecov)\n",
    "    \n",
    "    \n",
    "    #sigma_observed     = T.outer(binaryY[:,n], binaryY[:,n])*Cov+(binaryY_unobs*T.identity_like(Cov))\n",
    "    sigma_unobs_obs         = (T.outer(binaryY_unobs, T.neq(Y[:,n], zero)))*Cov\n",
    "    idxs3                   = T.neq(sigma_unobs_obs, zero2).nonzero()\n",
    "    little_sigma_unobs_obs = sigma_unobs_obs[:,idxs].reshape((D, s[n])) \n",
    "    #sigma_observed_inv = T.nlinalg.MatrixInverse()(sigma_observed)\n",
    "    dummyY             = T.zeros(D)\n",
    "    \n",
    "     \n",
    "    #draw the mean vector dummyY from N(0, WWT+sigma^2I) using computationally fast trick\n",
    "    dummy_results, dummy_updates= theano.scan(lambda prior_result, sigma, zY, W, zK: \n",
    "                                              T.sqrt(sigma)[0]*zY+T.dot(W,zK) + prior_result,\n",
    "                                              sequences=None,\n",
    "                                              outputs_info= T.zeros(D),\n",
    "                                              non_sequences=[sigma, zY, W, zK],\n",
    "                                              n_steps=R)\n",
    "    \n",
    "    dummyY       = dummy_results[-1]\n",
    "    dummyY       /= R\n",
    "    dummyY_obs   = dummyY[idxs]\n",
    "    dummyY_unobs = binaryY_unobs*dummyY\n",
    "    y_est        = dummyY_unobs + T.dot(T.dot(little_sigma_unobs_obs, littlecov_inv), (y-dummyY_obs))\n",
    "    y_est        = (y_est*binaryY_unobs)-(1e6)*Mask[:,n]\n",
    "    #y_est        = y_est*binaryY_unobs + Y[:,n]*Mask[:,n]\n",
    "    \n",
    "    return [y_est, sigma_unobs_obs, littlecov_inv]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def MainBandit(count, indexlist, Mask, Y):\n",
    "    \n",
    "    limit = 500\n",
    "    R     = 10\n",
    "    construct_elbo_list = 0\n",
    "    construct_error_list = 0\n",
    "    \n",
    "    elbolist = SGD(Y, limit,construct_elbo_list, construct_error_list)\n",
    "    \n",
    "    [y_estimate, sigma_u_o_scan, sigma_ob_inv_scan], updates=theano.scan(fn=MVNormalScan_beta02,\n",
    "                                              sequences=T.arange(N),\n",
    "                                              outputs_info=None,\n",
    "                                              non_sequences=[Y, Mask, Cov, W, zY, zK, s])\n",
    "\n",
    "    y_estimate     = y_estimate.T\n",
    "    [value, index] = T.max_and_argmax(y_estimate, axis=None, keepdims=False)   \n",
    "    mf             = T.flatten(Mask)\n",
    "    mf             = T.inc_subtensor(mf[index],1)\n",
    "    Mask           = mf.reshape((D,N))\n",
    "    \n",
    "    indexlist      = T.set_subtensor(indexlist[count], index)\n",
    "    \n",
    "      \n",
    "    return indexlist,Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MainBandit2(count, indexlist, Mask,Y):\n",
    "    \n",
    "    limit = 500\n",
    "    R     = 10\n",
    "    construct_elbo_list = 0\n",
    "    \n",
    "    elbolist = SGD(Y, limit,construct_elbo_list, construct_error_list)\n",
    "    \n",
    "    [y_estimate, sigma_u_o_scan, sigma_ob_inv_scan], updates=theano.scan(fn=MVNormalScan_beta02,\n",
    "                                              sequences=T.arange(N),\n",
    "                                              outputs_info=None,\n",
    "                                              non_sequences=[Y, Mask, Cov, W, zY, zK, s])\n",
    "\n",
    "    y_estimate     = y_estimate.T\n",
    "    [value, index] = T.max_and_argmax(y_estimate, axis=None, keepdims=False)   \n",
    "    mf             = T.flatten(Mask)\n",
    "    mf             = T.inc_subtensor(mf[index],1)\n",
    "    Mask           = mf.reshape((D,N))\n",
    "    \n",
    "    #indexlist      = T.set_subtensor(indexlist[count], index)\n",
    "    indexlist.append(index.eval()) \n",
    "    return indexlist,Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ind2sub(array_shape, ind):\n",
    "    #ind[ind < 0] = -1\n",
    "    #ind[ind >= array_shape[0]*array_shape[1]] = -1\n",
    "    rows = np.floor(ind / array_shape[1])\n",
    "    cols = ind % array_shape[1]\n",
    "    return (int(rows), int(cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "502\n"
     ]
    }
   ],
   "source": [
    "count     = 0\n",
    "ratings   = []\n",
    "R         = 5\n",
    "\n",
    "[indices, Mask_evolve], updates = theano.scan(fn=MainBandit,\n",
    "                                               sequences = T.arange(maxit),\n",
    "                                               outputs_info = [indexlist,Mask],\n",
    "                                               non_sequences = Y)\n",
    "indexlistnp = indices[-1].eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nindexlist2 = []\\ncount = 0\\n\\nwhile count< maxit:\\n    count += 1\\n    print(count)\\n    indexlist2,Mask = MainBandit2(count, indexlist2, Mask,Y)\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "indexlist2 = []\n",
    "count = 0\n",
    "\n",
    "while count< maxit:\n",
    "    count += 1\n",
    "    print(count)\n",
    "    indexlist2,Mask = MainBandit2(count, indexlist2, Mask,Y)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ratings = []\n",
    "initial_obs = np.multiply([Masknp!=0], Mnp).flatten()\n",
    "ratings = initial_obs[initial_obs!=0].tolist()\n",
    "for i in range(np.size(indexlistnp)):\n",
    "    [r,c] = ind2sub(np.shape(Mnp), int(indexlistnp[i]))\n",
    "    ratings.append(Mnp[r,c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reward = np.cumsum(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-b24e802c2166>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#(np.multiply(Mnp, (1e-6)*Masknp)).flatten()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#best = Mnp.flatten()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mbest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mbest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mbest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'best' is not defined"
     ]
    }
   ],
   "source": [
    "#best = Mnp + 0.00001\n",
    "#best[Masknp] = 1e-6\n",
    "#best = best.flatten()\n",
    "#(np.multiply(Mnp, (1e-6)*Masknp)).flatten()\n",
    "#best = Mnp.flatten()\n",
    "best.sort()\n",
    "best[:] =  best[::-1]\n",
    "best = np.cumsum(best)\n",
    "\n",
    "random_reward = np.zeros(np.size(Mnp.flatten()))\n",
    "for i in range(10):\n",
    "    #random = Mnp + 0.00001\n",
    "    #random[Masknp] = 1e-6\n",
    "    #random =  random.flatten()\n",
    "    random = (np.multiply(Mnp, (1e-6)*Masknp)).flatten()\n",
    "    random = np.random.permutation(random)\n",
    "    random_reward += np.cumsum(random)/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "% pylab inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(best)\n",
    "plt.plot(reward)\n",
    "plt.plot(random_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(best[0:np.size(reward)]-reward)\n",
    "plt.plot(best-random_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "maxit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N*D"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
