{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python3.5/site-packages/theano/tensor/signal/downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.\n",
      "  \"downsample module has been moved to the theano.tensor.signal.pool module.\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import scipy.sparse as sp\n",
    "from theano import sparse\n",
    "import lasagne\n",
    "import time\n",
    "import scipy.stats as stats\n",
    "from collections import OrderedDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate a matrix from a multivariate normal distribution with low-rank covariance matrix\n",
    "KTRUE = 10\n",
    "K = 20\n",
    "N = 100\n",
    "D = 50\n",
    "maxit = 3*KTRUE*(N+D-KTRUE)\n",
    "\n",
    "np.random.seed(seed=10)\n",
    "\n",
    "w   = np.random.uniform(low=0.0, high=1.0, size=(D,KTRUE))\n",
    "var = 0.1\n",
    "covnp = w.dot(w.T)+var*np.eye(D)\n",
    "\n",
    "Mnp = np.random.multivariate_normal(np.zeros(D), covnp, N).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We use Theano for our model\n",
    "srng = T.shared_randomstreams.RandomStreams(seed=120)\n",
    "\n",
    "#Define Theano Variables\n",
    "Shared = lambda shape,name: theano.shared(value = np.ones(shape,dtype=theano.config.floatX),\n",
    "                                          name=name,borrow=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let Ynp represent our matrix of partial, noisy observations\n",
    "p      = 1.5*(maxit/20)/(N*D)\n",
    "#Masknp = np.random.binomial(N, p, size=(N,D)).T\n",
    "Masknp = stats.bernoulli.rvs(p, size=(D,N))\n",
    "Mask   = T.as_tensor_variable(Masknp)\n",
    "M      = T.as_tensor_variable(Mnp)\n",
    "Y      = Mask*M\n",
    "zeroY  = T.as_tensor_variable(np.zeros((D,N)))\n",
    "zero2  = T.as_tensor_variable(np.zeros((D,D)))\n",
    "zero   = T.as_tensor_variable(np.zeros(D))\n",
    "st     = T.sum(T.neq(Y, zeroY), axis = 0)\n",
    "s      = st.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.063"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N*D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Define variables \n",
    "W      = Shared((D,K), 'W')\n",
    "r      = Shared((K), 'r')\n",
    "Gamma  = Shared((1), 'Gamma')\n",
    "Gamma0 = Shared((1), 'Gamma0')\n",
    "c0     = Shared((1), 'c0')\n",
    "sigma  = Shared((1), 'sigma')\n",
    "\n",
    "t      = T.dscalar('t')\n",
    "\n",
    "#Define random variables for MVNscan component\n",
    "zY = srng.normal([D])\n",
    "zK = srng.normal([K])\n",
    "\n",
    "#For data given seqentially we need a different covariance matrix for each yn\n",
    "WWT=T.dot(W, W.T)\n",
    "Cov=Shared((D,D), 'Cov')\n",
    "Cov=WWT+sigma[0]*T.identity_like(WWT)\n",
    "\n",
    "\n",
    "#Define lists\n",
    "mParams = [W, r, Gamma, Gamma0, c0, sigma]\n",
    "\n",
    "#indexlist = Shared([maxit], 'indexlist')\n",
    "indexlist = theano.shared(value = np.zeros([maxit],dtype=np.int64),\n",
    "                                          name='indexlist',borrow=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Define Functions for Langevin Step\n",
    "\n",
    "def logJointScanFn(n, logLikelihood, Y, Cov, s):\n",
    "    \n",
    "    idxs          = T.neq(Y[:,n], zero).nonzero()\n",
    "    y             = Y[:,n][idxs]\n",
    "    idxs2         = T.neq(T.outer(Y[:,n], Y[:,n]), zero2).nonzero()\n",
    "    littlecov     = Cov[idxs2].reshape((s[n], s[n]))\n",
    "    logLikelihood +=(-1/2.0)*T.log(T.nlinalg.Det()(littlecov))-(1/2.0)*T.dot(y.T, T.dot(T.nlinalg.MatrixInverse()(littlecov), y))\n",
    "    \n",
    "    return logLikelihood\n",
    "\n",
    "\n",
    "\n",
    "def LogJ(mParams, Y, Cov, s):\n",
    "\n",
    "    W, r, Gamma, Gamma0, c0, sigma = mParams\n",
    "    #LogJt0=time.clock()\n",
    "    results, updates = theano.scan(fn=logJointScanFn,\n",
    "                                   sequences = np.arange(N),\n",
    "                                   outputs_info=[dict(initial= np.float64(0) ,taps=[-1])],\n",
    "                                   non_sequences=[Y, Cov, s])\n",
    "    logJoint  = results[-1]\n",
    "    logJoint2 = ((D*Gamma*T.log(Gamma))[0]*r).sum()-(D*T.gammaln(Gamma[0]*r)).sum()+((Gamma[0]*r-1)*T.log(W)).sum()-(Gamma[0]*W).sum() + (Gamma0*T.log(c0)-K*T.gammaln(Gamma0/K)+(Gamma0/K-1)[0]*(T.log(r)).sum()-(c0[0]*r).sum()-Gamma-Gamma0-c0)[0]\n",
    "    logJoint  += logJoint2\n",
    "\n",
    "    return(logJoint)\n",
    "\n",
    "def LangevinUpdates(t,logJ,mParams):\n",
    "    grads = theano.grad(logJ, mParams)\n",
    "    updates=OrderedDict()\n",
    "    for param, grad in zip(mParams,grads):\n",
    "        #print(\"gradient\")\n",
    "        #print(grad.eval())\n",
    "        step=0.01*(np.power((t+1), -1/2.0))*grad\n",
    "        updates[param]=T.minimum(T.maximum((param+step).astype(theano.config.floatX), 0.1*T.ones_like(param)), 50*T.ones_like(param))                                          \n",
    "    return updates\n",
    "\n",
    "def Projection(mParams):\n",
    "    W, r, Gamma, Gamma0, c0, sigma = mParams\n",
    "    W      = T.maximum(T.zeros_like(W),W)\n",
    "    r      = T.maximum(T.zeros_like(r),r)\n",
    "    Gamma  = T.maximum(T.zeros_like(Gamma),Gamma)\n",
    "    Gamma0 = T.maximum(T.zeros_like(Gamma0),Gamma0)\n",
    "    sigma  = T.maximum(T.zeros_like(sigma), sigma)\n",
    "    \n",
    "    return W, r, Gamma, Gamma0, sigma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Ytrue = Y.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef SGDfast(counter, W, r, Gamma, Gamma0, c0,Cov, s, tljlist, Y):\\n    \\n    logJ = LogJ(mParams,Y,Cov, s)\\n    param_updates=LangevinUpdates(counter,logJ, mParams)\\n    LangevinStep()\\n    tljlist      = T.set_subtensor(tljlist[counter], logJ)\\n    \\n    return W, r, Gamma, Gamma0, c0, Cov, s, tljlist\\n    \\ntljlist = theano.shared(value = np.zeros([maxit],dtype=np.int64),\\n                                          name='tljlist',borrow=True)\\nlimit = 100\\n[W2, r2, Gamma2, Gamma02, c02, Cov2, s2, tljlist2], updates = theano.scan(fn=SGDfast,\\n                                   sequences = T.arange(limit),\\n                                   outputs_info=[W, r, Gamma, Gamma0, c0, Cov, s, tljlist],\\n                                   non_sequences=Y)\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Stochastic Gradient Descent\n",
    "\n",
    "counter = 1\n",
    "\n",
    "logJ = LogJ(mParams,Y,Cov, s)\n",
    "param_updates=LangevinUpdates(counter, logJ, mParams)\n",
    "LangevinStep=theano.function(inputs=[], updates=param_updates)\n",
    "\n",
    "\n",
    "def SGD(Y, limit,construct_lj_list, construct_error_list):\n",
    "    counter = 1\n",
    "    logJ = LogJ(mParams,Y,Cov, s)\n",
    "    param_updates=LangevinUpdates(counter,logJ, mParams)\n",
    "\n",
    "    \n",
    "    #%%time\n",
    "\n",
    "    ljlist = []\n",
    "    errorlist = []\n",
    "    keepUpdating = True\n",
    "    if construct_lj_list==1:\n",
    "        while keepUpdating:\n",
    "            print(sigma.eval())\n",
    "            LangevinStep()\n",
    "            keepUpdating = False if counter>limit else True \n",
    "            # if construct_elbo_list==1, estimate ELBO by Monte Carlo every 20 steps\n",
    "            if counter%20==0:\n",
    "                ljlist.append(np.mean([logJ.eval() for i in range(40)]))\n",
    "                R = 10\n",
    "                if construct_error_list:\n",
    "                    [y_estimate, sigma_u_o_scan, sigma_ob_inv_scan], updates=theano.scan(fn=MVNormalScan_beta02,\n",
    "                                              sequences=T.arange(N),\n",
    "                                              outputs_info=None,\n",
    "                                              non_sequences=[Y, Mask, Cov, W, zY, zK, s])\n",
    "                    Yest = y_estimate.eval().T\n",
    "                    errorlist.append(np.linalg.norm(Yest- Ytrue))                \n",
    "            counter +=1\n",
    "    else:\n",
    "        while keepUpdating:\n",
    "            LangevinStep()\n",
    "            keepUpdating = False if counter>limit else True \n",
    "            counter += 1\n",
    "    print(counter)\n",
    "    \n",
    "    return ljlist, errorlist\n",
    "\n",
    "\"\"\"\n",
    "def SGDfast(counter, W, r, Gamma, Gamma0, c0,Cov, s, tljlist, Y):\n",
    "    \n",
    "    logJ = LogJ(mParams,Y,Cov, s)\n",
    "    param_updates=LangevinUpdates(counter,logJ, mParams)\n",
    "    LangevinStep()\n",
    "    tljlist      = T.set_subtensor(tljlist[counter], logJ)\n",
    "    \n",
    "    return W, r, Gamma, Gamma0, c0, Cov, s, tljlist\n",
    "    \n",
    "tljlist = theano.shared(value = np.zeros([maxit],dtype=np.int64),\n",
    "                                          name='tljlist',borrow=True)\n",
    "limit = 100\n",
    "[W2, r2, Gamma2, Gamma02, c02, Cov2, s2, tljlist2], updates = theano.scan(fn=SGDfast,\n",
    "                                   sequences = T.arange(limit),\n",
    "                                   outputs_info=[W, r, Gamma, Gamma0, c0, Cov, s, tljlist],\n",
    "                                   non_sequences=Y)\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#MVNormalScan constructs our estimate of the entire matrix using conditional multivariate normal\n",
    "\n",
    "def MVNormalScan_beta02(n, Y, Mask, Cov, W, zY, zK, s):\n",
    "    \n",
    "    #construct binaryY_unobs a vector of 1s and 0s where the ith coord is a 1 if we haven't seen the ith coord of y_n    \n",
    "    binaryY_unobs = T.eq(Y[:,n], zero)\n",
    "    #construct covariance of the observed entries where the rows/columns with nothing have a 1 on diag (so invertible)\n",
    "    idxs          = T.neq(Y[:,n], zero).nonzero()\n",
    "    y             = Y[:,n][idxs]\n",
    "    idxs2         = T.neq(T.outer(Y[:,n], Y[:,n]), zero2).nonzero()\n",
    "    littlecov     = Cov[idxs2].reshape((s[n], s[n]))\n",
    "    littlecov_inv = T.nlinalg.MatrixInverse()(littlecov)\n",
    "    \n",
    "    \n",
    "    #sigma_observed     = T.outer(binaryY[:,n], binaryY[:,n])*Cov+(binaryY_unobs*T.identity_like(Cov))\n",
    "    sigma_unobs_obs         = (T.outer(binaryY_unobs, T.neq(Y[:,n], zero)))*Cov\n",
    "    idxs3                   = T.neq(sigma_unobs_obs, zero2).nonzero()\n",
    "    little_sigma_unobs_obs = sigma_unobs_obs[:,idxs].reshape((D, s[n])) \n",
    "    #sigma_observed_inv = T.nlinalg.MatrixInverse()(sigma_observed)\n",
    "    dummyY             = T.zeros(D)\n",
    "    \n",
    "     \n",
    "    #draw the mean vector dummyY from N(0, WWT+sigma^2I) using computationally fast trick\n",
    "    dummy_results, dummy_updates= theano.scan(lambda prior_result, sigma, zY, W, zK: \n",
    "                                              T.sqrt(sigma)[0]*zY+T.dot(W,zK) + prior_result,\n",
    "                                              sequences=None,\n",
    "                                              outputs_info= T.zeros(D),\n",
    "                                              non_sequences=[sigma, zY, W, zK],\n",
    "                                              n_steps=R)\n",
    "    \n",
    "    dummyY       = dummy_results[-1]\n",
    "    dummyY       /= R\n",
    "    dummyY_obs   = dummyY[idxs]\n",
    "    dummyY_unobs = binaryY_unobs*dummyY\n",
    "    y_est        = dummyY_unobs + T.dot(T.dot(little_sigma_unobs_obs, littlecov_inv), (y-dummyY_obs))\n",
    "    y_est        = (y_est*binaryY_unobs)-(1e6)*Mask[:,n]\n",
    "    #y_est        = y_est*binaryY_unobs + Y[:,n]*Mask[:,n]\n",
    "    \n",
    "    return [y_est, sigma_unobs_obs, littlecov_inv]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "R = 10\n",
    "[ljlist, errlist] = SGD(Y, 1000, 1 ,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "% pylab inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(ljlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "errlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def MainBandit(count, indexlist, Mask, Y):\n",
    "    \n",
    "    limit = 1000\n",
    "    R     = 10\n",
    "    construct_lj_list = 0\n",
    "    construct_error_list = 0\n",
    "    \n",
    "    ljlist = SGD(Y, limit,construct_lj_list, construct_error_list)\n",
    "    \n",
    "    [y_estimate, sigma_u_o_scan, sigma_ob_inv_scan], updates=theano.scan(fn=MVNormalScan_beta02,\n",
    "                                              sequences=T.arange(N),\n",
    "                                              outputs_info=None,\n",
    "                                              non_sequences=[Y, Mask, Cov, W, zY, zK, s])\n",
    "\n",
    "    y_estimate     = y_estimate.T\n",
    "    [value, index] = T.max_and_argmax(y_estimate, axis=None, keepdims=False)   \n",
    "    mf             = T.flatten(Mask)\n",
    "    mf             = T.inc_subtensor(mf[index],1)\n",
    "    Mask           = mf.reshape((D,N))\n",
    "    \n",
    "    indexlist      = T.set_subtensor(indexlist[count], index)\n",
    "    \n",
    "      \n",
    "    return indexlist,Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MainBandit2(count, indexlist, Mask,Y):\n",
    "    \n",
    "    limit = 1000\n",
    "    R     = 10\n",
    "    construct_elbo_list = 0\n",
    "    \n",
    "    elbolist = SGD(Y, limit,construct_elbo_list, construct_error_list)\n",
    "    \n",
    "    [y_estimate, sigma_u_o_scan, sigma_ob_inv_scan], updates=theano.scan(fn=MVNormalScan_beta02,\n",
    "                                              sequences=T.arange(N),\n",
    "                                              outputs_info=None,\n",
    "                                              non_sequences=[Y, Mask, Cov, W, zY, zK, s])\n",
    "\n",
    "    y_estimate     = y_estimate.T\n",
    "    [value, index] = T.max_and_argmax(y_estimate, axis=None, keepdims=False)   \n",
    "    mf             = T.flatten(Mask)\n",
    "    mf             = T.inc_subtensor(mf[index],1)\n",
    "    Mask           = mf.reshape((D,N))\n",
    "    \n",
    "    #indexlist      = T.set_subtensor(indexlist[count], index)\n",
    "    indexlist.append(index.eval()) \n",
    "    return indexlist,Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ind2sub(array_shape, ind):\n",
    "    #ind[ind < 0] = -1\n",
    "    #ind[ind >= array_shape[0]*array_shape[1]] = -1\n",
    "    rows = np.floor(ind / array_shape[1])\n",
    "    cols = ind % array_shape[1]\n",
    "    return (int(rows), int(cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1002\n"
     ]
    }
   ],
   "source": [
    "count     = 0\n",
    "ratings   = []\n",
    "R         = 5\n",
    "\n",
    "[indices, Mask_evolve], updates = theano.scan(fn=MainBandit,\n",
    "                                               sequences = T.arange(maxit),\n",
    "                                               outputs_info = [indexlist,Mask],\n",
    "                                               non_sequences = Y)\n",
    "indexlistnp = indices[-1].eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "indexlist2 = []\n",
    "count = 0\n",
    "\n",
    "while count< maxit:\n",
    "    count += 1\n",
    "    print(count)\n",
    "    indexlist2,Mask = MainBandit2(count, indexlist2, Mask,Y)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ratings = []\n",
    "initial_obs = np.multiply([Masknp!=0], Mnp).flatten()\n",
    "ratings = initial_obs[initial_obs!=0].tolist()\n",
    "for i in range(np.size(indexlistnp)):\n",
    "    [r,c] = ind2sub(np.shape(Mnp), int(indexlistnp[i]))\n",
    "    ratings.append(Mnp[r,c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reward = np.cumsum(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#best = Mnp + 0.00001\n",
    "#best[Masknp] = 1e-6\n",
    "#best = best.flatten()\n",
    "#(np.multiply(Mnp, (1e-6)*Masknp)).flatten()\n",
    "best = Mnp.flatten()\n",
    "best.sort()\n",
    "best[:] =  best[::-1]\n",
    "best = np.cumsum(best)\n",
    "\n",
    "random_reward = np.zeros(np.size(Mnp.flatten()))\n",
    "for i in range(10):\n",
    "    #random = Mnp + 0.00001\n",
    "    #random[Masknp] = 1e-6\n",
    "    #random =  random.flatten()\n",
    "    random = (np.multiply(Mnp, (1e-6)*Masknp)).flatten()\n",
    "    random = np.random.permutation(random)\n",
    "    random_reward += np.cumsum(random)/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "% pylab inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(best)\n",
    "plt.plot(reward)\n",
    "plt.plot(random_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(best[0:np.size(reward)]-reward)\n",
    "plt.plot(best-random_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "maxit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logJ.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
