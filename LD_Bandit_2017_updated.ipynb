{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python3.5/site-packages/theano/tensor/signal/downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.\n",
      "  \"downsample module has been moved to the theano.tensor.signal.pool module.\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import scipy.sparse as sp\n",
    "from theano import sparse\n",
    "import lasagne\n",
    "import time\n",
    "import scipy.stats as stats\n",
    "from collections import OrderedDict\n",
    "import sys \n",
    "sys.setrecursionlimit(50000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate a matrix from a multivariate normal distribution with low-rank covariance matrix\n",
    "KTRUE = 1\n",
    "K = 5\n",
    "N = 50\n",
    "D = 20\n",
    "maxit = 3*KTRUE*(N+D-KTRUE)\n",
    "#maxit = N*D\n",
    "\n",
    "np.random.seed(seed=10)\n",
    "\n",
    "#c0np = np.random.gamma(1,1)\n",
    "#gamma0np = np.random.gamma(1,1)\n",
    "#gammanp = np.random.gamma(1,1)\n",
    "#rnp = np.random.gamma(gamma0np/KTRUE, c0np, size=(KTRUE))\n",
    "#w = np.zeros((D,KTRUE))\n",
    "#for k in range(KTRUE):\n",
    "#    print(gammanp*rnp[k])\n",
    "#    print(gammanp)\n",
    "#    w[:,k] = np.random.gamma(gammanp*rnp[k]+1e-20, gammanp+1e-20, size = (D))\n",
    "    \n",
    "\n",
    "w   = np.random.uniform(low=0.0, high=1.0, size=(D,KTRUE))\n",
    "#Introduce some complexity into w\n",
    "#w     = np.random.beta(a = 2, b = 5, size = (D,KTRUE))\n",
    "#maskw = stats.bernoulli.rvs(0.8, size=(D,KTRUE))\n",
    "#w     = np.multiply(w,maskw)\n",
    "var = 0.1\n",
    "covnp = w.dot(w.T)+var*np.eye(D)\n",
    "\n",
    "Mnp = np.random.multivariate_normal(np.zeros(D), covnp, N).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "207"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random_w_init = np.random.uniform(low=0.01, high=2.0, size=(D,K))\n",
    "random_r_init = np.random.uniform(low = 0.01, high = 2.0, size = K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We use Theano for our model\n",
    "srng = T.shared_randomstreams.RandomStreams(seed=120)\n",
    "\n",
    "#Define Theano Variables\n",
    "Shared = lambda shape,name: theano.shared(value = np.ones(shape,dtype=theano.config.floatX),\n",
    "                                          name=name,borrow=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rand_index = srng.random_integers(low = 0, high = N-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let Ynp represent our matrix of partial, noisy observations\n",
    "#p = 0.03\n",
    "prob      = 16*(maxit/(N*D))/(20)\n",
    "#prob = 1\n",
    "observe = np.random.permutation(np.arange(N*D))[1:int(np.floor(prob*N*D))]\n",
    "Masknp = np.zeros(N*D)\n",
    "Masknp[observe] = 1\n",
    "observerow = np.random.randint(0, high=D, size=np.maximum(N,D))\n",
    "observecol = np.arange(N)\n",
    "Masknp = Masknp.reshape((D,N))\n",
    "Masknp[observerow, observecol] = 1\n",
    "initial_obs = np.multiply([Masknp!=0], Mnp).flatten()\n",
    "ratings = initial_obs[initial_obs!=0].tolist()\n",
    "#p = 0.08\n",
    "#Masknp = np.random.binomial(N, p, size=(N,D)).T\n",
    "#Masknp = stats.bernoulli.rvs(p, size=(D,N))\n",
    "#Masknp[1,:] = 1\n",
    "Mask   = Shared((D,N), 'Mask')\n",
    "Mask.set_value(Masknp)\n",
    "M      = T.as_tensor_variable(Mnp)\n",
    "Y      = Mask*M\n",
    "zeroY  = T.as_tensor_variable(np.zeros((D,N)))\n",
    "zero2  = T.as_tensor_variable(np.zeros((D,D)))\n",
    "zero   = T.as_tensor_variable(np.zeros(D))\n",
    "st     = T.sum(T.neq(Y, zeroY), axis = 0)\n",
    "s      = st.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Define variables \n",
    "W      = Shared((D,K), 'W')\n",
    "W.set_value(random_w_init)\n",
    "r      = Shared((K), 'r')\n",
    "r.set_value(random_r_init)\n",
    "Gamma  = Shared((1), 'Gamma')\n",
    "Gamma0 = Shared((1), 'Gamma0')\n",
    "c0     = Shared((1), 'c0')\n",
    "sigma  = Shared((1), 'sigma')\n",
    "\n",
    "t      = T.dscalar('t')\n",
    "\n",
    "#Define random variables for MVNscan component\n",
    "zY = srng.normal([D])\n",
    "zK = srng.normal([K])\n",
    "\n",
    "#For data given seqentially we need a different covariance matrix for each yn\n",
    "WWT=T.dot(W, W.T)\n",
    "Cov=Shared((D,D), 'Cov')\n",
    "Cov=WWT+sigma[0]*T.identity_like(WWT)\n",
    "#Cov = T.as_tensor_variable(covnp, name= 'Cov')\n",
    "\n",
    "#Define lists\n",
    "mParams = [W, r, Gamma, Gamma0, c0, sigma]\n",
    "\n",
    "#indexlist = Shared([maxit], 'indexlist')\n",
    "indexlist = theano.shared(value = np.zeros([maxit,2],dtype=np.int64),\n",
    "                                          name='indexlist',borrow=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Define Functions for Langevin Step\n",
    "\n",
    "def logJointScanFn(n, logLikelihood, Y, Cov, Mask):\n",
    "    \n",
    "    #idxs          = T.neq(Y[:,n], zero).nonzero()\n",
    "    #y             = Y[:,n][idxs]\n",
    "    #idxs2         = T.neq(T.outer(Y[:,n], Y[:,n]), zero2).nonzero()\n",
    "    \n",
    "    #littlecov     = Cov[idxs2].reshape((s[n], s[n]))\n",
    "    #logLikelihood +=(-1/2.0)*T.log(T.nlinalg.Det()(littlecov))-(1/2.0)*T.dot(y.T, T.dot(T.nlinalg.MatrixInverse()(littlecov), y))\n",
    "    \n",
    "    #numpy_IncompleteId=np.zeros((D,D))\n",
    "    #Mask=C.gpu_from_host(T.outer(Yobs_theano[:,n], Yobs_theano[:,n]).reshape((D,D)))\n",
    "    \n",
    "    Partial_Cov    = T.outer(Mask[:,n], Mask[:,n])*Cov + (1-Mask[:,n])*T.identity_like(Cov)\n",
    "    logLikelihood += (-1/2.0)*T.log(T.nlinalg.Det()(Partial_Cov))-(1/2.0)*T.dot(Y[:,n].T, T.dot(T.nlinalg.MatrixInverse()(Partial_Cov), Y[:,n]))\n",
    "    \n",
    "    return logLikelihood\n",
    "\n",
    "def LogJ(mParams, Y, Cov, Mask):\n",
    "\n",
    "    W, r, Gamma, Gamma0, c0, sigma = mParams\n",
    "    #LogJt0=time.clock()\n",
    "    \n",
    "    results, updates = theano.scan(fn=logJointScanFn,\n",
    "                                   sequences = np.arange(N),\n",
    "                                   outputs_info=[dict(initial= np.float64(0) ,taps=[-1])],\n",
    "                                   non_sequences=[Y, Cov, Mask])\n",
    "    \n",
    "    #logLikelihood = sigma[0]\n",
    "    #for n in range(N):\n",
    "    #    logLikelihood = logJointScanFn(n, logLikelihood, Y, Cov, s)\n",
    "    logJoint = results[-1]\n",
    "    \n",
    "    #logJoint  = results[-1]\n",
    "    logJoint2 = ((D*Gamma*T.log(Gamma))[0]*r).sum()-(D*T.gammaln(Gamma[0]*r)).sum()+((Gamma[0]*r-1)*T.log(W)).sum()-(Gamma[0]*W).sum() + (Gamma0*T.log(c0)-K*T.gammaln(Gamma0/K)+(Gamma0/K-1)[0]*(T.log(r)).sum()-(c0[0]*r).sum()-Gamma-Gamma0-c0)[0]\n",
    "    logJoint  += logJoint2\n",
    "\n",
    "    return(logJoint)\n",
    "\n",
    "def adadelta2(loss_or_grads, W, r, Gamma, Gamma0, c0, sigma, learning_rate=1.0, rho=0.95, epsilon=1e-6):\n",
    "    \"\"\" \n",
    "    References\n",
    "    ----------\n",
    "    .. [1] Zeiler, M. D. (2012):\n",
    "           ADADELTA: An Adaptive Learning Rate Method.\n",
    "           arXiv Preprint arXiv:1212.5701.\n",
    "    \"\"\"\n",
    "    params = [W, r, Gamma, Gamma0, c0, sigma]\n",
    "    grads = get_or_compute_grads(loss_or_grads, params)\n",
    "    updates = OrderedDict()\n",
    "\n",
    "    # Using theano constant to prevent upcasting of float32\n",
    "    one = T.constant(1)\n",
    "\n",
    "    for param, grad in zip(params, grads):\n",
    "        value = param.get_value(borrow=True)\n",
    "        # accu: accumulate gradient magnitudes\n",
    "        accu = theano.shared(np.zeros(value.shape, dtype=value.dtype),\n",
    "                             broadcastable=param.broadcastable)\n",
    "        # delta_accu: accumulate update magnitudes (recursively!)\n",
    "        delta_accu = theano.shared(np.zeros(value.shape, dtype=value.dtype),\n",
    "                                   broadcastable=param.broadcastable)\n",
    "\n",
    "        # update accu (as in rmsprop)\n",
    "        accu_new = rho * accu + (one - rho) * grad ** 2\n",
    "        updates[accu] = accu_new\n",
    "        #accu = accu_new\n",
    "\n",
    "        # compute parameter update, using the 'old' delta_accu\n",
    "        update = (grad * T.sqrt(delta_accu + epsilon) /\n",
    "                  T.sqrt(accu_new + epsilon))\n",
    "        #updates[param] = param - learning_rate * update\n",
    "        updates[param] = T.minimum(T.maximum((param - learning_rate * update).astype(theano.config.floatX), (1e-10)*T.ones_like(param)), 10*T.ones_like(param))\n",
    "        #param = T.minimum(T.maximum((param - learning_rate * update).astype(theano.config.floatX), (1e-10)*T.ones_like(param)), 10*T.ones_like(param))\n",
    "        # update delta_accu (as accu, but accumulating updates)\n",
    "        delta_accu_new = rho * delta_accu + (one - rho) * update ** 2\n",
    "        updates[delta_accu] = delta_accu_new\n",
    "        #delta_accu = delta_accu_new\n",
    "\n",
    "    return updates\n",
    "\n",
    "def get_or_compute_grads(loss_or_grads, params):\n",
    "    \"\"\"Helper function returning a list of gradients\n",
    "    \"\"\"\n",
    "    if any(not isinstance(p, theano.compile.SharedVariable) for p in params):\n",
    "        raise ValueError(\"params must contain shared variables only. If it \"\n",
    "                         \"contains arbitrary parameter expressions, then \"\n",
    "                         \"lasagne.utils.collect_shared_vars() may help you.\")\n",
    "    if isinstance(loss_or_grads, list):\n",
    "        if not len(loss_or_grads) == len(params):\n",
    "            raise ValueError(\"Got %d gradient expressions for %d parameters\" %\n",
    "                             (len(loss_or_grads), len(params)))\n",
    "        return loss_or_grads\n",
    "    else:\n",
    "        return theano.grad(loss_or_grads, params)\n",
    "    \n",
    "    \n",
    "#MVNormalScan constructs our estimate of the entire matrix using conditional multivariate normal\n",
    "\n",
    "def MVNormalScan_beta02(n, Y, Mask, Cov, W, zY, zK, s):\n",
    "    \n",
    "    #construct binaryY_unobs a vector of 1s and 0s where the ith coord is a 1 if we haven't seen the ith coord of y_n    \n",
    "    binaryY_unobs = T.eq(Y[:,n], zero)\n",
    "    #construct covariance of the observed entries where the rows/columns with nothing have a 1 on diag (so invertible)\n",
    "    idxs          = T.neq(Y[:,n], zero).nonzero()\n",
    "    y             = Y[:,n][idxs]\n",
    "    idxs2         = T.neq(T.outer(Y[:,n], Y[:,n]), zero2).nonzero()\n",
    "    littlecov     = Cov[idxs2].reshape((s[n], s[n]))\n",
    "    littlecov_inv = T.nlinalg.MatrixInverse()(littlecov)\n",
    "    \n",
    "    #sigma_observed     = T.outer(binaryY[:,n], binaryY[:,n])*Cov+(binaryY_unobs*T.identity_like(Cov))\n",
    "    sigma_unobs_obs         = (T.outer(binaryY_unobs, T.neq(Y[:,n], zero)))*Cov\n",
    "    idxs3                   = T.neq(sigma_unobs_obs, zero2).nonzero()\n",
    "    little_sigma_unobs_obs = sigma_unobs_obs[:,idxs].reshape((D, s[n])) \n",
    "    #sigma_observed_inv = T.nlinalg.MatrixInverse()(sigma_observed)\n",
    "    dummyY             = T.zeros(D)\n",
    "    \n",
    "    #draw the mean vector dummyY from N(0, WWT+sigma^2I) using computationally fast trick\n",
    "    dummy_results, dummy_updates= theano.scan(lambda prior_result, sigma, zY, W, zK: \n",
    "                                              T.sqrt(sigma)[0]*zY+T.dot(W,zK) + prior_result,\n",
    "                                              sequences=None,\n",
    "                                              outputs_info= T.zeros(D),\n",
    "                                              non_sequences=[sigma, zY, W, zK],\n",
    "                                              n_steps=R)\n",
    "    \n",
    "    dummyY       = dummy_results[-1]\n",
    "    dummyY       /= R\n",
    "    dummyY_obs   = dummyY[idxs]\n",
    "    dummyY_unobs = binaryY_unobs*dummyY\n",
    "    y_est        = dummyY_unobs + T.dot(T.dot(little_sigma_unobs_obs, littlecov_inv), (y-dummyY_obs))\n",
    "    y_est        = (y_est*binaryY_unobs)-(1e6)*Mask[:,n]\n",
    "    #y_est        = y_est*binaryY_unobs + Y[:,n]*Mask[:,n]\n",
    "    \n",
    "    return [y_est, sigma_unobs_obs, littlecov_inv]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Ytrue = Y.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Gradient Descent- to do \"limit\" steps of gradient descent call AdaDeltaStep2()\n",
    "limit = 200\n",
    "\n",
    "logJ = LogJ(mParams,Y,Cov, Mask)\n",
    "[results, mParam_updates] = theano.scan(fn = adadelta2, \n",
    "                                      sequences = None,\n",
    "                                      non_sequences = [-logJ, W, r, Gamma, Gamma0, c0, sigma],\n",
    "                                      outputs_info = None,\n",
    "                                      n_steps = limit)\n",
    "\n",
    "AdaDeltaStep2=theano.function(inputs=[], updates=mParam_updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nprint('Before')\\nprint(Cov.eval())\\nlogJ = LogJ(mParams,Y,Cov, Mask)\\nprint(logJ.eval())\\nAdaDeltaStep2()\\nprint('After')\\nprint(Cov.eval())\\nlogJ = LogJ(mParams,Y,Cov, Mask)\\nprint(logJ.eval())\\n\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This serves to test how well, given whatever percent of data observed you set through variable \"p\", \n",
    "#we can estimate the covariance matrix\n",
    "#% pylab inline\n",
    "#import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "\"\"\"\n",
    "print('Before')\n",
    "print(Cov.eval())\n",
    "logJ = LogJ(mParams,Y,Cov, Mask)\n",
    "print(logJ.eval())\n",
    "AdaDeltaStep2()\n",
    "print('After')\n",
    "print(Cov.eval())\n",
    "logJ = LogJ(mParams,Y,Cov, Mask)\n",
    "print(logJ.eval())\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if any(not isinstance(p, theano.compile.SharedVariable) for p in mParams):\n",
    "    print(\"Strange Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def MainBandit2(count, Mask, Masknp, W, r, sigma, Gamma, Gamma0, c0, Y, s, Cov, indexlistnp):\n",
    "    \n",
    "    limit = 1000\n",
    "    R     = 10\n",
    "    construct_lj_list = 0\n",
    "    construct_error_list = 0\n",
    "    tt = time.clock()\n",
    "        \n",
    "    logJ = LogJ(mParams,Y,Cov, Mask)\n",
    "    AdaDeltaStep2()\n",
    "    #print('adadelta')\n",
    "    #print(time.clock()-tt)\n",
    "    \n",
    "    #[ljlist, errlist, W, r, sigma, Gamma, Gamma0, c0] = SGD(Y, limit,construct_lj_list, construct_error_list, W, r, sigma, Gamma, Gamma0, c0)\n",
    "    \n",
    "    #tt = time.clock()\n",
    "    #sigma.eval()\n",
    "    #print('update time')\n",
    "    #print(time.clock()-tt)\n",
    "    \n",
    "    # Pick col at random and draw from that column\n",
    "    #col_ind = rand_index.eval()    \n",
    "    #[y_est, sigma_unobs_obs, littlecov_inv] = MVNormalScan_beta02(col_ind, Y, Mask, Cov, W, zY, zK, s)\n",
    "    \n",
    "    \n",
    "    [y_est, sigma_u_o_scan, sigma_ob_inv_scan], updates=theano.scan(fn=MVNormalScan_beta02,\n",
    "                                              sequences=T.arange(N),\n",
    "                                              outputs_info=None,\n",
    "                                              non_sequences=[Y, Mask, Cov, W, zY, zK, st])\n",
    "    \n",
    "    #print('mvnscan')\n",
    "    #print(time.clock()-tt)\n",
    "    #y_est.eval()\n",
    "    #print('yest time')\n",
    "    #print(time.clock()-tt)\n",
    "    \n",
    "    #y_estnp = 0\n",
    "    #for rr in range(R):\n",
    "    #    y_estnp += y_est.eval()\n",
    "    #y_estnp /= R\n",
    "    \n",
    "    #row_ind = np.argmax(y_estnp)\n",
    "    \n",
    "    #print('y_estimate')\n",
    "    #print(y_estimate[1,:].eval())\n",
    "    tt = time.clock()\n",
    "    [value, index] = T.max_and_argmax(y_est.T)\n",
    "    \n",
    "    indnp = index.eval()\n",
    "    \n",
    "    #print('index choice')\n",
    "    #print(time.clock() - tt)\n",
    "    \n",
    "    mf = Masknp.flatten()\n",
    "    mf[indnp] = 1\n",
    "    Masknp = mf.reshape((D,N))\n",
    "    #Masknp[row_ind, col_ind] = 1\n",
    "    Mask.set_value(Masknp)\n",
    "    #print('rating')\n",
    "    #print(Mnp[row_ind, col_ind])\n",
    "    #print('expected rating')\n",
    "    #print(y_estnp[row_ind])\n",
    "\n",
    "    #print(T.size(Mask).eval())\n",
    "    \n",
    "    #ON CPU IT MIGHT BE FASTER TO EVAL INDEX EACH ITERATION, BUT PERHAPS USE THEANO INDEXLIST FOR GPU \n",
    "    \n",
    "    #indexlist      = T.set_subtensor(indexlist[count,0], index)\n",
    "    #indexlist      = T.set_subtensor(indexlist[count,1], n)\n",
    "    tt = time.clock()\n",
    "    #indexlistnp[count,0] = row_ind\n",
    "    #indexlistnp[count,1] = col_ind\n",
    "    indexlistnp[count] = indnp\n",
    "    #print('eval time')\n",
    "    #print(time.clock()-tt)\n",
    "    #print(r.eval())\n",
    "    s = st.eval()\n",
    "    \n",
    "    \n",
    "    return Mask, Masknp, W, r, sigma, Gamma, Gamma0, c0, s, Cov, indexlistnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ind2sub(array_shape, ind):\n",
    "    #ind[ind < 0] = -1\n",
    "    #ind[ind >= array_shape[0]*array_shape[1]] = -1\n",
    "    rows = np.floor(ind / array_shape[1])\n",
    "    cols = ind % array_shape[1]\n",
    "    return (int(rows), int(cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last 50 iters time: 1.3775960000000396, Bandit is: 0.0, percent complete.\n",
      "last 50 iters time: 71.80104399999999, Bandit is: 0.24154589371980675, percent complete.\n",
      "last 50 iters time: 72.6961, Bandit is: 0.4830917874396135, percent complete.\n",
      "last 50 iters time: 72.98492899999997, Bandit is: 0.7246376811594203, percent complete.\n",
      "last 50 iters time: 72.87777600000004, Bandit is: 0.966183574879227, percent complete.\n"
     ]
    }
   ],
   "source": [
    "count     = 0\n",
    "ratings   = [] \n",
    "R         = 20\n",
    "\n",
    "tt        = time.clock()\n",
    "indexlistnp = np.zeros(maxit)\n",
    "for i in range(maxit):\n",
    "    [Mask, Masknp, W, r, sigma, Gamma, Gamma0, c0, s, Cov, indexlistnp]  = MainBandit2(count, Mask,Masknp, W, r, sigma, Gamma, Gamma0, c0, Y, s, Cov, indexlistnp)\n",
    "    count = count + 1\n",
    "    if i%50 == 0 and i>1:\n",
    "        print(\"last 50 iters time: {}, Bandit is: {} percent complete.\".format(time.clock()-tt, i/maxit))\n",
    "        tt = time.clock()\n",
    "    elif i==maxit:\n",
    "        print(\"last set of iters time: {}, Bandit is: {} percent complete.\".format(time.clock()-tt, i/maxit))\n",
    "        tt = time.clock()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 569.,  977.,  369.,  929.,  919.,  178.,  386.,   32.,  557.,\n",
       "        928.,  586.,  719.,  160.,  910.,  379.,  576.,  381.,  726.,\n",
       "        926.,  710.,   11.,   40.,  550.,  590.,  760.,  703.,  729.,\n",
       "        960.,  378.,  737.,  979.,  376.,  383.,  575.,  740.,  179.,\n",
       "         29.,  361.,  707.,  676.,  582.,  526.,  978.,   28.,   37.,\n",
       "        933.,  169.,  587.,  976.,   26.,  572.,  725.,  126.,  736.,\n",
       "        778.,  940.,  932.,  561.,  190.,   36.,   16.,    0.,  350.,\n",
       "        551.,  210.,  722.,  153.,  690.,  540.,  990.,  558.,  175.,\n",
       "        886.,  779.,  554.,   27.,   31.,  700.,  714.,  226.,   45.,\n",
       "        745.,  528.,  769.,  229.,  186.,   18.,  595.,  594.,  519.,\n",
       "        975.,   10.,  525.,  360.,   19.,  382.,  565.,  712.,  172.,\n",
       "        679.,  282.,  503.,  500.,  353.,    3.,  953.,   14.,  387.,\n",
       "        753.,  732.,   24.,  581.,    8.,  507.,  536.,  653.,  950.,\n",
       "        537.,    7.,   12.,  969.,  187.,   25.,  371.,  512.,  532.,\n",
       "        397.,    9.,   33.,   42.,  562.,  103.,  375.,  140.,  203.,\n",
       "        182.,  125.,  100.,  972.,  162.,  136.,  826.,  363.,  527.,\n",
       "        775.,  228.,  388.,  987.,  395.,  107.,  599.,  675.,   49.,\n",
       "         15.,  219.,  678.,   35.,  399.,  650.,  354.,  368.,  982.,\n",
       "        945.,  731.,  137.,  704.,  583.,  164.,  504.,  410.,  580.,\n",
       "        686.,  394.,  750.,  657.,  733.,  757.,  687.,  962.,  682.,\n",
       "        662.,  517.,  571.,  365.,  181.,  165.,  995.,  112.,  200.,\n",
       "        954.,  762.,  672.,  832.,  904.,  911.,  727.,  754.,  122.,\n",
       "        981.,  104.,  836.,  654.,  681.,  161.,  574.,   22.,  840.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexlistnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0068191825\n",
      "-0.024633375308\n",
      "0.512274070355\n",
      "1.19572541925\n",
      "1.3508970022\n",
      "1.16286765369\n",
      "0.807439624887\n",
      "0.640716753719\n",
      "1.03104805307\n",
      "0.707187064648\n",
      "1.1445349999\n",
      "0.434683992488\n",
      "1.25119824837\n",
      "1.15205675469\n",
      "0.930948400754\n",
      "1.36187999786\n",
      "0.479032306745\n",
      "1.26478193536\n",
      "1.0527461532\n",
      "1.47149354966\n",
      "0.649680248371\n",
      "0.916505508749\n",
      "0.790300916724\n",
      "1.12924084935\n",
      "0.955273319844\n",
      "0.699821901157\n",
      "1.26293983966\n",
      "1.03037640251\n",
      "0.840156530235\n",
      "0.271046215673\n",
      "0.589923825983\n",
      "0.965051838087\n",
      "0.0780788032567\n",
      "1.32589838782\n",
      "1.28670135333\n",
      "0.523141096964\n",
      "1.0952168488\n",
      "0.807232302495\n",
      "0.499874507197\n",
      "0.889857835561\n",
      "0.644981447927\n",
      "0.763913638048\n",
      "0.918123412139\n",
      "1.31273831822\n",
      "0.571482432867\n",
      "-0.356125263288\n",
      "0.864663060339\n",
      "0.795360031684\n",
      "0.728515558287\n",
      "1.031340086\n",
      "1.09484229083\n",
      "0.841045434213\n",
      "0.462864758849\n",
      "0.450473566941\n",
      "0.320647766432\n",
      "1.43358193973\n",
      "0.0177169280773\n",
      "-0.177919957555\n",
      "1.1703543954\n",
      "0.823182368077\n",
      "0.129729363247\n",
      "0.94184314057\n",
      "0.721830830265\n",
      "-0.161950668169\n",
      "0.754217498189\n",
      "0.827158686241\n",
      "0.697311448789\n",
      "0.632496935083\n",
      "0.334574153224\n",
      "1.2806053005\n",
      "-0.920212511564\n",
      "1.01662565672\n",
      "0.198302549851\n",
      "0.62894020489\n",
      "0.328606119279\n",
      "-0.154950927937\n",
      "0.156651078067\n",
      "1.35670188646\n",
      "0.0233448599196\n",
      "0.971100030132\n",
      "0.459379367807\n",
      "0.882976046242\n",
      "0.609633164922\n",
      "0.650759216226\n",
      "1.03359297615\n",
      "0.218891938841\n",
      "0.223245838476\n",
      "0.18868606501\n",
      "0.0336437626438\n",
      "0.108805084092\n",
      "1.54516249102\n",
      "1.33774403537\n",
      "0.759192544799\n",
      "1.36671965349\n",
      "0.746268559943\n",
      "0.723725747733\n",
      "0.345144090641\n",
      "0.50173429249\n",
      "0.542641810649\n",
      "0.948554153565\n",
      "0.1094787463\n",
      "0.989335560734\n",
      "1.12511729933\n",
      "1.18572112911\n",
      "1.44954338824\n",
      "1.61466820444\n",
      "0.0857988327517\n",
      "0.671056423247\n",
      "0.908537380957\n",
      "0.682002854153\n",
      "-0.13584488126\n",
      "0.365568986865\n",
      "-0.0459234908434\n",
      "0.573330082349\n",
      "1.15522577957\n",
      "0.348216024139\n",
      "0.152582181873\n",
      "0.617963617932\n",
      "0.470198687914\n",
      "0.596702655195\n",
      "0.955596884006\n",
      "0.579885065431\n",
      "1.16227445957\n",
      "-0.198007001129\n",
      "0.279814529745\n",
      "0.699610003685\n",
      "-0.156067842373\n",
      "-0.703593810038\n",
      "0.131622595925\n",
      "-0.151669600639\n",
      "1.03825954341\n",
      "1.31588524959\n",
      "0.800308960748\n",
      "1.51420423944\n",
      "1.02525014012\n",
      "1.01945010136\n",
      "0.87325855333\n",
      "0.52307290174\n",
      "-0.0738473180936\n",
      "0.493751602774\n",
      "0.961761529666\n",
      "1.2275050624\n",
      "-1.17644030741\n",
      "0.0889654544676\n",
      "0.393342138363\n",
      "0.484619690297\n",
      "-0.801494811012\n",
      "0.827185258627\n",
      "0.473605532733\n",
      "0.310102404865\n",
      "0.276717221031\n",
      "0.665550996363\n",
      "0.275639797251\n",
      "0.255329757574\n",
      "0.83865522144\n",
      "0.199828364156\n",
      "-1.04537331914\n",
      "-0.149175193413\n",
      "0.751925510317\n",
      "0.0741423764752\n",
      "0.103755433167\n",
      "0.934020683628\n",
      "0.401395724658\n",
      "0.574484239605\n",
      "0.244432800073\n",
      "0.632008661111\n",
      "0.650172024575\n",
      "-0.735493131657\n",
      "0.985600048826\n",
      "-0.201223598282\n",
      "-0.252461283985\n",
      "0.166681759738\n",
      "0.0789760540629\n",
      "0.865284824665\n",
      "0.0218110501448\n",
      "0.2176101152\n",
      "0.148545603613\n",
      "0.446394873128\n",
      "0.730950860599\n",
      "0.266945859972\n",
      "0.324360213798\n",
      "-1.17882869517\n",
      "-0.749668143478\n",
      "-0.0744482247642\n",
      "0.0973470147887\n",
      "-0.31072468437\n",
      "0.199541750001\n",
      "0.396103933978\n",
      "0.735314721169\n",
      "0.182374752777\n",
      "0.497007404492\n",
      "0.257668104479\n",
      "0.751508398307\n",
      "0.429318561397\n",
      "0.416650235708\n",
      "0.311493659413\n",
      "0.260153484322\n",
      "0.507484411593\n",
      "0.646174236525\n",
      "0.307991363096\n",
      "1.21887251753\n",
      "0.0456412952397\n",
      "-0.0382180920479\n",
      "-0.0377385369498\n",
      "0.1575201315\n",
      "-0.141210200857\n",
      "0.677242077577\n"
     ]
    }
   ],
   "source": [
    "#indexlistnp = indexlist.eval()\n",
    "#indexlist[-1].eval()\n",
    "#ratings = []\n",
    "for i in range(maxit):\n",
    "    [row,col] = ind2sub(np.shape(Mnp), int(indexlistnp[i]))\n",
    "    ratings.append (Mnp[row,col])\n",
    "    print(Mnp[row,col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indexlistnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indexlistnp[0:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reward = np.cumsum(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#best = Mnp + 0.00001\n",
    "#best[Masknp] = 1e-6\n",
    "#best = best.flatten()\n",
    "#(np.multiply(Mnp, (1e-6)*Masknp)).flatten()\n",
    "best = Mnp.flatten()\n",
    "best.sort()\n",
    "best[:] =  best[::-1]\n",
    "best = np.cumsum(best)\n",
    "\n",
    "random_reward = np.zeros(np.size(Mnp.flatten()))\n",
    "for i in range(10):\n",
    "    #random = Mnp + 0.00001\n",
    "    #random[Masknp] = 1e-6\n",
    "    #random =  random.flatten()\n",
    "    #random = (np.multiply(Mnp, (1e-6)*Masknp)).flatten()\n",
    "    random = Mnp.flatten()\n",
    "    random = np.random.permutation(random)\n",
    "    random_reward += np.cumsum(random)/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pylab import has clobbered these variables: ['random', 'var']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x10e25e1d0>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEACAYAAABbMHZzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxIcU/iIiPqTwFxHxof8PfN2UwJf4vMsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10de09470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#PLOT ACCUMULATED REWARDS\n",
    "\n",
    "% pylab inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "length        = np.minimum(np.size(reward), np.size(best))\n",
    "reward        = reward[0:length]\n",
    "best          = best[0:length]\n",
    "random_reward = random_reward[0:length]\n",
    "\n",
    "plt.plot(best)\n",
    "plt.plot(reward)\n",
    "plt.plot(random_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0068191825018205,\n",
       " -0.024633375307954508,\n",
       " 0.51227407035499228,\n",
       " 1.1957254192494027,\n",
       " 1.3508970022005855,\n",
       " 1.1628676536856055,\n",
       " 0.80743962488700805,\n",
       " 0.64071675371900827,\n",
       " 1.0310480530704078,\n",
       " 0.70718706464799685,\n",
       " 1.1445349999023806,\n",
       " 0.43468399248817458,\n",
       " 1.2511982483709678,\n",
       " 1.1520567546938205,\n",
       " 0.93094840075362739,\n",
       " 1.3618799978638414,\n",
       " 0.47903230674510172,\n",
       " 1.2647819353626986,\n",
       " 1.0527461532031011,\n",
       " 1.4714935496627886,\n",
       " 0.64968024837112603,\n",
       " 0.91650550874924785,\n",
       " 0.79030091672443215,\n",
       " 1.1292408493507151,\n",
       " 0.9552733198444715,\n",
       " 0.69982190115674758,\n",
       " 1.2629398396626941,\n",
       " 1.0303764025081443,\n",
       " 0.84015653023539294,\n",
       " 0.27104621567291798,\n",
       " 0.58992382598311743,\n",
       " 0.9650518380874743,\n",
       " 0.07807880325673934,\n",
       " 1.3258983878202697,\n",
       " 1.2867013533271359,\n",
       " 0.52314109696368349,\n",
       " 1.0952168487956073,\n",
       " 0.8072323024950917,\n",
       " 0.49987450719738469,\n",
       " 0.88985783556099562,\n",
       " 0.64498144792705303,\n",
       " 0.76391363804754298,\n",
       " 0.91812341213866322,\n",
       " 1.3127383182181043,\n",
       " 0.57148243286744516,\n",
       " -0.35612526328768596,\n",
       " 0.86466306033871587,\n",
       " 0.79536003168412273,\n",
       " 0.72851555828698966,\n",
       " 1.031340085995617,\n",
       " 1.0948422908342861,\n",
       " 0.84104543421286349,\n",
       " 0.46286475884948747,\n",
       " 0.45047356694097285,\n",
       " 0.32064776643212062,\n",
       " 1.4335819397330547,\n",
       " 0.017716928077341709,\n",
       " -0.17791995755501114,\n",
       " 1.1703543953967297,\n",
       " 0.82318236807668044,\n",
       " 0.12972936324702022,\n",
       " 0.94184314056979879,\n",
       " 0.72183083026463657,\n",
       " -0.16195066816907031,\n",
       " 0.75421749818939743,\n",
       " 0.8271586862412097,\n",
       " 0.69731144878936169,\n",
       " 0.6324969350825026,\n",
       " 0.33457415322430889,\n",
       " 1.2806053004983906,\n",
       " -0.92021251156392703,\n",
       " 1.016625656715453,\n",
       " 0.19830254985054879,\n",
       " 0.62894020488978686,\n",
       " 0.32860611927947192,\n",
       " -0.15495092793684337,\n",
       " 0.15665107806705519,\n",
       " 1.3567018864572167,\n",
       " 0.023344859919625031,\n",
       " 0.97110003013233692,\n",
       " 0.45937936780663363,\n",
       " 0.88297604624172055,\n",
       " 0.60963316492234509,\n",
       " 0.65075921622554,\n",
       " 1.033592976147083,\n",
       " 0.21889193884056593,\n",
       " 0.22324583847638871,\n",
       " 0.18868606501004603,\n",
       " 0.033643762643839843,\n",
       " 0.10880508409151317,\n",
       " 1.5451624910151409,\n",
       " 1.3377440353688781,\n",
       " 0.75919254479939047,\n",
       " 1.3667196534941992,\n",
       " 0.74626855994321717,\n",
       " 0.72372574773296039,\n",
       " 0.34514409064103396,\n",
       " 0.50173429249040746,\n",
       " 0.54264181064923989,\n",
       " 0.94855415356467332,\n",
       " 0.10947874629967895,\n",
       " 0.98933556073395068,\n",
       " 1.1251172993252758,\n",
       " 1.185721129114846,\n",
       " 1.4495433882377931,\n",
       " 1.6146682044361866,\n",
       " 0.085798832751721107,\n",
       " 0.67105642324659931,\n",
       " 0.90853738095700209,\n",
       " 0.68200285415273987,\n",
       " -0.13584488125979083,\n",
       " 0.36556898686520295,\n",
       " -0.045923490843358623,\n",
       " 0.57333008234877192,\n",
       " 1.1552257795748095,\n",
       " 0.34821602413857944,\n",
       " 0.15258218187335276,\n",
       " 0.61796361793164045,\n",
       " 0.47019868791414365,\n",
       " 0.59670265519519916,\n",
       " 0.95559688400568987,\n",
       " 0.57988506543137341,\n",
       " 1.1622744595698637,\n",
       " -0.19800700112900105,\n",
       " 0.27981452974504056,\n",
       " 0.69961000368507187,\n",
       " -0.15606784237276108,\n",
       " -0.70359381003764221,\n",
       " 0.13162259592505482,\n",
       " -0.15166960063868146,\n",
       " 1.0382595434052493,\n",
       " 1.3158852495879541,\n",
       " 0.80030896074772429,\n",
       " 1.5142042394419482,\n",
       " 1.0252501401152461,\n",
       " 1.0194501013596675,\n",
       " 0.87325855332972546,\n",
       " 0.52307290173963794,\n",
       " -0.073847318093628572,\n",
       " 0.49375160277362162,\n",
       " 0.96176152966640183,\n",
       " 1.2275050623977164,\n",
       " -1.1764403074122507,\n",
       " 0.088965454467635652,\n",
       " 0.39334213836291687,\n",
       " 0.48461969029685847,\n",
       " -0.8014948110119231,\n",
       " 0.82718525862727754,\n",
       " 0.47360553273315825,\n",
       " 0.3101024048648014,\n",
       " 0.27671722103139262,\n",
       " 0.66555099636317661,\n",
       " 0.27563979725124044,\n",
       " 0.25532975757400883,\n",
       " 0.83865522144013294,\n",
       " 0.19982836415609301,\n",
       " -1.0453733191392629,\n",
       " -0.14917519341265234,\n",
       " 0.75192551031668309,\n",
       " 0.074142376475185887,\n",
       " 0.10375543316707134,\n",
       " 0.93402068362791091,\n",
       " 0.40139572465786627,\n",
       " 0.57448423960517536,\n",
       " 0.24443280007253343,\n",
       " 0.63200866111132492,\n",
       " 0.65017202457521717,\n",
       " -0.73549313165737029,\n",
       " 0.98560004882566099,\n",
       " -0.20122359828218073,\n",
       " -0.25246128398460727,\n",
       " 0.16668175973788329,\n",
       " 0.078976054062853671,\n",
       " 0.86528482466490242,\n",
       " 0.021811050144841471,\n",
       " 0.21761011519954238,\n",
       " 0.14854560361313254,\n",
       " 0.44639487312799553,\n",
       " 0.73095086059876024,\n",
       " 0.26694585997196435,\n",
       " 0.32436021379804769,\n",
       " -1.1788286951720495,\n",
       " -0.74966814347776323,\n",
       " -0.074448224764241247,\n",
       " 0.097347014788738015,\n",
       " -0.31072468437018963,\n",
       " 0.19954175000093036,\n",
       " 0.396103933978387,\n",
       " 0.73531472116945229,\n",
       " 0.18237475277748441,\n",
       " 0.49700740449184599,\n",
       " 0.25766810447884886,\n",
       " 0.75150839830651051,\n",
       " 0.42931856139657243,\n",
       " 0.41665023570785886,\n",
       " 0.31149365941265872,\n",
       " 0.26015348432230523,\n",
       " 0.50748441159268531,\n",
       " 0.64617423652526873,\n",
       " 0.3079913630961883,\n",
       " 1.2188725175268222,\n",
       " 0.045641295239664349,\n",
       " -0.038218092047897639,\n",
       " -0.03773853694983887,\n",
       " 0.15752013149972052,\n",
       " -0.14121020085700151,\n",
       " 0.67724207757695343]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#PLOT REGRET\n",
    "\n",
    "plt.plot(best-reward)\n",
    "plt.plot((best-random_reward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
